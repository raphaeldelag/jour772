---
title: "lab_06_update"
author: "Rob Wells/Derek Willis"
date: "2025-10-15"
output: html_document
---
Student name: Raphael Romero Ruiz
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Combining and merging tables

## Chapter 17

### Task 1: Load libraries and settings

**Task** Run the following code codeblock below to load the tidyverse library and turn off scientific notation.

```{r}
# turn off sci notation
options(scipen=999)
library(tidyverse)
library(lubridate)
library(janitor)
```

Often, as data journalists, we’re looking at data across time or at data stored in multiple tables. And to do that, we need to often need to merge that data together.

Depending on what we have, we may just need to stack data on top of each other to make new data. If we have 2019 data and 2018 data and we want that to be one file, we stack them. If we have a dataset of cows in counties and a dataset of populations in county, we’re going to join those two together on the county – the common element.

### Task 2: Stacking data using bind_rows

We have Maryland county voter registration data from five different elections in five different files. They have the same record layout and the same number of counties (plus Baltimore City).

Because they are in identical file format -- same number of columns and data types - we can combine them into a single dataframe using bind_rows.

```{r}
county_voters_2016 <- read_csv("data/county_voters_2016.csv")
county_voters_2018 <- read_csv("data/county_voters_2018.csv")
county_voters_2020 <- read_csv("data/county_voters_2020.csv")
county_voters_2022 <- read_csv("data/county_voters_2022.csv")
county_voters_2024 <- read_csv("data/county_voters_2024.csv")
```


These datasets have the same number of columns, all with the same names, so if we want to merge them together to compare them over time, we can stack them together using bind_rows. Since we have five dataframes, we’re going to need to pass them as a list, meaning they’ll be enclosed inside the list function.

### Task 3: Using bind_rows

**Task** Combine the five files into a single data frame using the bind_rows() function, along with list(). Add a description of what this code does to your reference notebook.

```{r}
# bind_rows with list
county_voters_combined <- bind_rows(list(county_voters_2016, county_voters_2018, county_voters_2020, county_voters_2022, county_voters_2024))
View(county_voters_combined)
```

There are plenty of uses for bind_rows: any regularly updated data that comes in the same format like crime reports or award recipients or player game statistics. Or election results.

## Joining data

More complicated is when you have two separate tables that are connected by a common element or elements. We perform that using join.

Let’s start by reading in some Maryland 2020 county population data:

### Task 4: Loading population data

**Task** Load the Maryland 2020 county population data


```{r}
    maryland_population <- read_csv('data/maryland_population_2020.csv')
```



One of the columns we have is called county, which is what we have in our county_voters_2024 dataframe.

To put the Maryland population data and voter registration data together, we need to use something called a join.

There are different kinds of joins. It’s better if you think of two tables sitting next to each other.

-   A left_join takes all the records from the left table and only the records that match in the right one.

-   A right_join does the same thing.

-   An inner_join takes only the records where they are equal.

-   A full_join which returns all rows of both, regardless of if there’s a match – but I’ve never once had a use for a full join.

In this case, both of our tables have a column called county that has the same characteristics: values in both look identical, including how they distinguish Baltimore City from Baltimore County. This is important, because joins work on exact matches.

We can do this join multiple ways and get a similar result. We can put the population file on the left and the registration data on the right and use a left join to get them all together. And we use join_by() to join by the correct columns. I’m going to count the rows at the end. The reason I’m doing this is important: 

**Rule 1 in joining data is having an idea of what you are expecting to get.**
So with a left join with population on the left, I have 24 rows, so I expect to get 24 rows when I’m done.

### Task 5: Join population and voter data

**Task** Run the following code to join Maryland population data and the 2020 voter registration data together using the common column county as the key. How many rows are there now? How many *should* there be? 


```{r}
# with nrow included to show row total
maryland_population_with_voters <- maryland_population |> left_join(county_voters_2024, join_by(COUNTY))
```

Remove the nrow and run it again for yourself. By default, dplyr will do a “natural” join, where it’ll match all the matching columns in both tables. So if we take out the by, it’ll use all the common columns between the tables. That may not be right in every instance but let’s try it. If it works, we should get 24 rows.

And if it works, the resulting dataframe will be 10 columns: 9 from county_voters_2024 and one from maryland_population (the County column will be the matching column).

### Task 6: Looking at Joined Data

**Task** Examine the combined data

```{r}
# without nrow
maryland_population |> left_join(county_voters_2024, join_by(COUNTY))
```



Now, with our joined data, we can answer questions in a more useful way. But joins can do even more than just bring data together; they can include additional data to enable you to ask more sophisticated questions. Right now we have registered voters and total population. But we can do more.

Let’s try adding more Maryland demographic data to the mix. Using a file describing the 18-and-over population (from which eligible voters come) from the state’s data catalog, we can read it into R:

### Task 8: Add the Demographic Data

**Task** Load the Maryland demographic data

```{r}
maryland_demographics <- read_csv('data/maryland_demographics.csv')
```

Again, we can use a left_join to make our demographic data available. This time we’ll need to specify the two fields to join because they do not have identical names. We’ll use COUNTY from our population data and NAME from the demographic data.

**The order matters - the first column is from the dataframe you name first.**

### Task 9: Join demographic data to combined voting/population data

**Task** Join the demographic data to the our combined voting/population data by the COUNTY and NAME columns

```{r}
maryland_population_with_voters_and_demographics <- maryland_population |> left_join(maryland_population_with_voters, join_by(COUNTY)) %>% left_join(maryland_demographics, join_by(COUNTY==NAME)) 
```

Now we’ve got population data and demographic data by county. That means we can draw from both datasets in asking our questions. For example, we could see the counties with the highest 18+ Black population as a percentage of all population 18 and over and also the percentage of Democrats in that county.

We can get this by using mutate and arrange:

### Task 10: Asking Demographic Questions

**Task** Using mutate, let's find the county with the highest 18+ Black population as a percentage of all population 18 and over and also the percentage of Democrats in that county. 

```{r}
maryland_population_with_voters_and_demographics |>
  mutate(pct_black_18_plus = (pop_black/pop_18_over)*100, pct_dems = (DEM/TOTAL)*100) |> 
  arrange(desc(pct_black_18_plus)) |> 
  select(COUNTY, pct_black_18_plus, pct_dems)
```

If you know Maryland political demographics, this result isn’t too surprising, but Somerset County - the state’s 2nd smallest in terms of population - stands out for its Black population, which is a greater percentage than Baltimore County and Montgomery County.

### Task 11: Fixing Join Problems

Sometimes joins look like they should work but don't. Often this is due to the two columns you're joining on having different data types: joining a <chr> column to a <dbl> column, for example. Let's walk through an example of that using some demographic data by zip code.

**Task** Run the following code to load the Zip Code Tabulation Area data for Maryland. What's the datatype of the ZCTA5N? column? 

```{r}
maryland_zcta <- read_csv('data/maryland_zcta.csv')
glimpse(maryland_zcta)
```

The column we're interested in, ZCTA5N, is a <dbl> column - it's a number. We want it to be a <chr> column - text - so we can use it in joins with our next step in this tutorial.

**Task** Run the following code to change the datatype of ZCTA5N from numeric to character. What's the datatype of ZCTA5N now? 

```{r}
maryland_zcta <- maryland_zcta |> mutate(across(ZCTA5N, as.character))
```

Now we can join this dataframe to other zip code data where the zip code column is text, not numbers.

------------------------------------------------------------------------

# Lab 06 Updated


## Getting Started

This lab involves combining and joining data to make it more useful and to ask some questions about it. We'll use some more 911 overdose call data to do this. The first thing we want to do is to combine multiple counties' data into a single dataframe so that we can ask some questions. First, let's combine data from Cecil, Carroll and Allegany counties into a new dataframe.

*Before* you combine them you'll need to clean up some of the column names to make the data easier to work with - make sure you have loaded the library to do that. You also need to make sure that each column has the same name and datatype (you can check the datatypes using `glimpse`). If any of them does not, you need to fix that.

You will find the 911 call data for Allegany, Cecil, and Carroll counties in the data folder.

## Lab Task 1: Load and combine the call data from Allegany, Cecil, and Carroll counties using bind_rows. Call it "combined_911" 
```{r}
# load and combine the call data from those three counties
allegany_911 <- read_csv("data/allegany_911.csv") %>% 
  clean_names()
carroll_911 <- read_csv("data/carroll_911.csv") %>% 
  clean_names()
cecil_911 <- read_csv("data/cecil_911.csv") %>% 
  clean_names()
```

```{r}
combined_911 <- bind_rows(list(allegany_911, carroll_911, cecil_911))
glimpse(combined_911)
```


Next, join demographic data with Baltimore City 911 calls. 

## Lab Task 2: Load the Baltimore City 911 data and the maryland_zcta demographic data from the data folder. Join them based on the zip code. Call the dataframe "baltimore_911_with_demographics"

Remember, the zip codes in both dataframes must be the same datatype (and should be characters). You should start with your Baltimore City 911 dataframe in creating your join.

```{r}
# load and join the Baltimore-related data
baltimore_911 <- read_csv("data/baltimore_911.csv") %>% 
  clean_names() %>% 
  mutate(across(zip_code, as.character))
#maryland_zcta already loaded 
```

```{r}
baltimore_911_with_demographics <- baltimore_911 %>% 
  left_join(maryland_zcta, join_by(zip_code == ZCTA5N))
```


## Answer questions

Q1. Let's start with the "combined_911" data from Allegany, Cecil and Carroll counties.

Q1a: Write code to generate a dataframe that shows the total number of calls for each county. 


```{r}
combined_911 %>%
  count(county, name = "total_calls") %>% 
  arrange(desc(total_calls))
```
Q1b: Write the answer: What's the order of counties from most calls to least?

**Write the answer:**
The county with the most calls is Carroll, then Cecil, then Allegany. 


Q2. Use the "combined_911" data. Write code to do the following:

-- Add a column for the month of each call
-- Show the total number of calls per county and month. 

```{r}
combined_911_summary <- combined_911 %>%
  mutate(month = month(date)) %>%
  group_by(month, county) %>% 
  summarise(calls = n())
```


Q2a: Are there any outliers or noteworthy results? Describe the general pattern of the results.

**Write answer here:**
Cecil County shows a clear outlier in August with 55 calls — the largest single‑month total among the three counties and a sharp jump from 40 the month before. The monthly counts reach a peak in the summertime months when the highest counts are recorded. The volume of calls overall falls mostly between the mid 20s to low 40s. Allegany county appears to have the most volatile range, topping at a volume of 50 calls to the county's low point in November with 17.  Carroll county is the most stable month‑to‑month, typically between the high 30s and 40s.
Q2b: Use "combined_911" data and write code to calculate the most calls per county and location. 

```{r}
combined_911 %>%
  count(county, location, name = "calls") %>%
  group_by(county) %>%
  filter(calls == max(calls)) %>%
  arrange(county)
```

Q2c: Which location had the most calls - where and what is that location?

**Write answer here:**
The county that had the most 911 calls was Cecil County, specifically at "314 GROVE NECK RD EARLEVILLE, MD" with 15 calls.

Table of results
Allegany: "19410 OLD DANS ROCK RD SW" — 5 calls
Carroll: "10 GEORGE ST" — 7 calls
Cecil: "314 GROVE NECK RD EARLEVILLE, MD" — 15 calls 


Q3. Now let's use the Baltimore City data, "baltimore_911_with_demographics." 

Write code to filter for calls in zip codes where the percentage of under 18 population is at least 75%.

Next, show the zip code and population and how many calls occurred in each of those zip codes.

```{r}
#understanding PLT18SP: Percent of population under 18 years old and POP100: Total population from maryland_zcta data: https://mdgeodata.md.gov/imap/rest/services/Demographics/MD_CensusData/FeatureServer/1 
baltimore_911_with_demographics %>%
  filter(!is.na(PLT18SP) & PLT18SP >= 75) %>%
  count(zip_code, POP100, name = "calls") %>%
  arrange(desc(calls))
```


Q3a: Where are those zip codes in the city?

**Write the answer here:**
Those seven ZCTAs are spread across Baltimore — the highest counts are in West/Southwest and central parts of the city:

21217 — West Baltimore (large Westside neighborhoods)
21223 — Southwest/industrial corridor (southwest part of the city)
21202 and 21201 — downtown / central Baltimore (Inner Harbor / central business district / nearby neighborhoods)
21213 and 21205 — East / central Baltimore neighborhoods
21216 — northwest / near central-north neighborhoods

Q4: Continuing with the baltimore_911_with_demographics data. Take the table you just created in Q3 and modify it.

Add a column that calculates the number of calls per 1,000 people for those zip codes. To calculate a per capita rate, you might find this short guide handy: [https://observablehq.com/\@palewire/per-capita-calculator](https://observablehq.com/@palewire/per-capita-calculator){.uri}.

```{r}
baltimore_911_with_demographics %>%
  filter(!is.na(PLT18SP) & PLT18SP >= 75) %>%
  count(zip_code, POP100, name = "calls") %>%
  mutate(calls_per_1000 = calls / POP100 * 1000) %>%
  arrange(desc(calls_per_1000))
```


Q4a: Which zip code has the highest rate of calls per 1,000 people? Find the neighborhoods in that zip code that are listed in the data - you can use group_by or distinct to do this. 


Do an internet search: What are some of those neighborhoods, and what else can you tell me about the population there?

**Write the answer here:**
21217 has the highest burden both in raw calls (774) and rate (20.9 calls per 1,000 people).
21217 includes Sandtown‑Winchester, Upton, and Druid Heights — predominantly Black neighborhoods with rich cultural histories that have experienced economic disinvestment, higher rates of poverty and crime, and ongoing revitalization efforts.```