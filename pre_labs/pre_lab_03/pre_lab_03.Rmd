---
title: "pre_lab_03.Rmd"
author: "Derek Willis"
date: "2025-01-15"
output: html_document
---
---
student_name: Raphael Romero Ruiz
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(scipen=999)
```

## About this notebook

This notebook contains code and explanatory text that your should review and run as you read through two chapters on data cleaning from the course textbook, "Data Journalism with R and the Tidyverse". Answer questions and edit the document as directed.

Running this notebook will help you understand key data analysis methods and concepts that you will put into practice during this week's lab.

When you are finished running the code in this notebook, you will push changes to your course GitHub repo, and upload the link to ELMS as instructed.

## Data Cleaning, Part I

### Task 1: Load libraries and settings

**Task** Run the following code in the gray-colored codeblock below to load the tidyverse library and turn off scientific notation.

```{r}
# Remove scientific notation
options(scipen=999)
# Load the tidyverse   
library(tidyverse)
```

### Task 2: Load data

**Task** Load some [Maryland state government payments data](https://opendata.maryland.gov/Budget/State-of-Maryland-Payments-Data-FY2008-to-FY2024/7syw-q4cy) by running the following code. We'll use the guess_max() function as an argument to use the first 10 rows to set the data type. What does the first line of the red Warning message that prints out when you load the data say? What happens when you follow its instructions? Answer below. **Answer**

The first line in the warning message tells me that the there was an issue reading in the data. When I follow the instructions, using 'problems()' in the console, a window into the columns in the data frame pops up. 



```{r}
payments <- read_csv("data/State_of_Maryland_Payments_Data__FY2008_to_FY2024_20250115.csv", guess_max=10)
```

### Task 3: Reload data

**Task** Run the following codeblock to reload the data, using every row to set the data types. Does it show any parsing errors when you run? Answer below **Answer**

No parsing isssues here. Seems like 'Vendor Zip' was reclassified as a chr value rather than dbl.
```{r}
payments <- read_csv("data/State_of_Maryland_Payments_Data__FY2008_to_FY2024_20250115.csv", guess_max=369008)
```

### Task 4: Examine the data with glimpse

**Task** Run the following codeblock to glimpse the data. What data type is the "Vendor Name" field? What data type is the "Amount" field? What data type is the "Date" column? Answer below. **Answer**

The "Vendor Name" column is a "chr" or character field. The "Amount" column is a "dbl" or numerical field. The "Date" column is a "chr" or character field. 
```{r}
glimpse(payments)
```

Things that should be characters -- like agency name, vendor name -- are characters (chr). Things that should be numbers (dbl) -- like amount and fiscal year -- are numbers. We've seen before that sometimes dates aren't defined as date datatypes by R - we can fix that using `lubridate`.

### Task 5: Detect wrong spatial data

The second smell we can find in code is **wrong spatial data**. Spatial data means data that refers to some geography; in this dataset the only geographical element is the vendor's zip code. Zip codes should be, at a minimum, five characters long (although composed of numbers, zip codes aren't used as numbers).

We can check to see if any of the zip codes are less than five characters by using [a function called `str_length`](https://stringr.tidyverse.org/reference/str_length.html) inside a filter.

**Task** Run the following codeblock to group by the vendor's zip code and show any that are less than five characters in length. How many zip codes do not have five characters? What do you think explains those records? **Answer**

There are 553 zip codes that do not have five characters. This likely has something to do with how the data was formulated.
```{r}
payments |>
  group_by(`Vendor Zip`) |>
  filter(str_length(`Vendor Zip`) < 5) |> 
  summarise(
    count=n()
  ) |>
  arrange(desc(count))
```

### Task 6: Load Maryland grant and loan data

Let's now look at **gaps in data**. These often occur when you have a date or time element in your data, but there are other potential gaps, too. To illustrate those, we're going to introduce some Maryland state grant and loan data from 2009 forward. Let's load it and take a look:

**Task** Run the following codeblock to load Maryland state government grant and loan data

```{r}
md_grants_loans <- read_csv("data/State_of_Maryland_Grant_and_Loan_Data__FY2009_to_FY2022_20250115.csv")
```

Each row represents a recipient of state grant or loan, along with information about their location and the state agency that provided the money. When we talk about gaps, often they indicate the administrative rules. Here's an example: let's count the number of payments in each category (Grant or Loan) by year in this dataset.

### Task 7: Looking at categories

**Task** Run the following codeblock and describe below what each line is doing. Looking at the results, what jumps out at you as potentially problematic? **Answer**

We are taking the "md_grants_loans" data frame and grouping the rows by both "Fiscal Year" and "Category" column. Then we are counting the number of rows for each group and arranging them by fiscal year.  

```{r}
md_grants_loans |> 
  group_by(`Fiscal Year`, Category) |> 
  summarize(count = n()) |> 
  arrange(`Fiscal Year`)
```

Any time you are going to focus on a column for analysis, you should check for unusual values. Are there any unusually large values or unusually small values? Are there any values that raise immediate questions about the data? Let's look at the smallest amounts in the grants and loan data.

### Task 8: Find outliers

**Task** Run the following code to arrange the grants & loan data so that the smallest amount is first. Describe what you see. **Answer**

I am seeing the "md_grants_loans" data frame sorted by the smallest to greatest numerical value in the "Amount" column. Skimming through the data the thing that stands out to me is that several character values in the "Zip Code" column include the zip + four. 

```{r}
md_grants_loans |> 
  arrange(Amount)
```

## Data Cleaning, Part II

### Task 1: Install janitor

**Task** Run the following codeblock to install the janitor package.

```{r}
install.packages('janitor')
```

### Task 2: Load janitor

**Task** Run the following code to load janitor.

```{r}
library(janitor)
```

Let's continue with our Maryland grants and loans data that we worked with in the previous chapter. There are a number of issues with this data set that might get in the way of asking questions and receiving accurate answers. They are:

-   The column names have spaces in them. This isn't a deal-breaker, as we used this dataframe previously. But it does require that you do some things differently when writing code, and ideally you don't want spaces in your column names.
-   Inconsistent capitalization across multiple columns. Sometimes the grantee is capitalized, and other times not. Portions of the grantor name are sometimes capitalized. This issue will ruin your ability to count and add things using those columns.
-   The zip field mixes five digit ZIP codes and nine digit ZIP codes, and some of the records include spaces. If we wanted to group and count the number of loans in a given ZIP code, this inconsistency would not let us do that correctly.
-   The category column is inconsistent and has some missing values.

Let's get cleaning. Our goal will be to build up one block of code that does all the necessary cleaning in order to answer this question: which zip code has gotten the most amount of money from the Maryland Tourism Board?

### Task 3: Use clean_names()

**Task** Run the following codeblock to use the `clean_names()` function from janitor to standardize column names. How does it change the headers? Answer below. **Answer**
The headers have been standardized. All the characters in the column headers have been made under case and and spaces have been replaced with underscores. 
```{r}
# cleaning function
cleaned_md_grants_loans <- md_grants_loans |>
  clean_names()

# display the cleaned dataset
cleaned_md_grants_loans
```

### Task 4: Use rename()

**Task** Run the following codeblock to use the clean_names() function from janitor to standardize column names and then use rename() to change the "grantor" column to "source". With `rename()` the new name comes first!

```{r}
# cleaning function
cleaned_md_grants_loans <- md_grants_loans |>
  clean_names() |> 
  rename(source = grantor)

# display the cleaned dataset
cleaned_md_grants_loans
```

Right now the `source`, `grantee` and `description` columns have inconsistent capitalization. We can fix that using a mutate statement and a function that changes the case of text called `str_to_upper()`. We'll use the same columns, overwriting what's in there since all we're doing is changing case.

### Task 5: Using str_to_upper() to standardize case

**Task** Run the following codeblock to use str_to_upper() to make the source, grantee and description columns upper-cased. Describe what each line is doing. **Answer**

We are making a new data frame using the cleaned up data in "md_data_loans" by standardizing the column heads using "clean_names()". Then the line "rename(source = grantor)" renaming the "grantor" column header to "source". The characters in the "source", "grantee" and "description" rows in the new data frame, "cleaned_md_grants_loans", are then capitalized. Then we are displaying the new data frame. 
```{r}
# cleaning function
cleaned_md_grants_loans <- md_grants_loans |>
  clean_names() |> 
  rename(source = grantor) |> 
  mutate(source = str_to_upper(source), grantee = str_to_upper(grantee), description = str_to_upper(description))

# display the cleaned dataset
cleaned_md_grants_loans
```

### Task 6: Check for duplicate rows

**Task** Run the following codeblock to check for duplicate rows using get_dupes(). How many duplicates are possible? **Answer**
There are 29 possible duplicates. 

```{r}
cleaned_md_grants_loans |>
  get_dupes()
```

### Task 7: Get rid of duplicate rows

**Task** Run the following codeblock to use distinct() to get rid of duplicate rows. How many rows does the new dataframe have? Answer below. **Answer**

There are 19,453 rows in the new data frame.
```{r}
# cleaning function
cleaned_md_grants_loans <- md_grants_loans |>
  clean_names() |> 
  rename(source = grantor) |> 
  mutate(source = str_to_upper(source), grantee = str_to_upper(grantee), description = str_to_upper(description)) |> 
  distinct()

# display the cleaned dataset
cleaned_md_grants_loans
```

### Task 8: Clean up ZIP code

The rest of the problems with this data set all have to do with inconsistent format of values in a few of the columns. To fix these problems, we're going to make use of mutate() in concert with "string functions" -- special functions that allow us to clean up columns stored as character strings. The tidyverse package `stringr` has lots of useful string functions that you can look up!

Let's start by cleaning up the zip field. Remember, some of the rows had a five-digit ZIP code, while others had a nine-digit ZIP code, separated by a hyphen or not.

We're going to write code that tells R to make a new column for our zips, keeping the first five digits on the left, and get rid of anything after that by using `mutate()` in concert with `str_sub()`, from the `stringr` package.

**Task** Run the following codeblock to use str_sub() to convert the ZIP codes that have nine digits to five digits, creating a new column. Look at the difference in the result - what changed? **Answer**
A new column is made named "zip5" in the "cleaned_md_grants_loans". The characters in that rows in that column and only five digits long. 
```{r}
# cleaning function
cleaned_md_grants_loans <- md_grants_loans |>
  clean_names() |> 
  rename(source = grantor) |> 
  mutate(source = str_to_upper(source), grantee = str_to_upper(grantee), description = str_to_upper(description)) |> 
  distinct() |>
  mutate(zip5 = str_sub(zip_code, start=1L, end=5L))


# display the cleaned dataset
cleaned_md_grants_loans
```

### Task 9: Clean up zip5 field more with case_when()

**Task** Run the following codeblock to use case_when() to change clear non-zip codes into NA values.

```{r}
# cleaning function
cleaned_md_grants_loans <- md_grants_loans |>
  clean_names() |> 
  rename(source = grantor) |> 
  mutate(source = str_to_upper(source), grantee = str_to_upper(grantee), description = str_to_upper(description)) |> 
  distinct() |>
  mutate(zip5 = str_sub(zip_code, start=1L, end=5L)) |>
  mutate(zip5 = case_when(
    zip5 == "Vario" ~ NA,
    zip5 == "UB7 O" ~ NA,
    zip5 == "UB7 " ~ NA,
    .default = zip5
  ))

# display the cleaned dataset
cleaned_md_grants_loans
```

### Task 10: Answer our question!

**Task** Write and run code to answer our original question: which zip code has gotten the most amount of money from the Maryland Tourism Board? Where is that zip code, and does that zip code make sense to you as the top recipient? Write a sentence describing the top result. **Answer**

The top result is for the 21202 which covers most of central Baltimore city. This zip code makes sense as it is an area that includes the Inner Harbor area which is suppose to be a big area for visitors to go to when traveling to Baltimore. The Maryland Tourism Board would want to invest the most amount of money here. 

```{r}

cleaned_md_grants_loans %>%
  filter(source == "MARYLAND TOURISM BOARD") %>% 
  group_by(zip5) %>%
  summarise(total_amt = sum(amount, na.rm=TRUE)) %>%
  arrange(desc(total_amt))
  
```
